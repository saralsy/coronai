{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os, sys\n",
    "import json, pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepaths = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/samsung/2020-03-13/biorxiv_medrxiv/biorxiv_medrxiv/'\n",
    "dataset_filepaths['biorxiv_medrxiv'] = [os.path.join(path, e) for e in os.listdir(path) if e.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/samsung/2020-03-13/comm_use_subset/comm_use_subset/'\n",
    "dataset_filepaths['comm_use_subset'] = [os.path.join(path, e) for e in os.listdir(path) if e.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/samsung/2020-03-13/noncomm_use_subset/noncomm_use_subset/'\n",
    "dataset_filepaths['noncomm_use_subset'] = [os.path.join(path, e) for e in os.listdir(path) if e.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/samsung/2020-03-13/pmc_custom_license/pmc_custom_license/'\n",
    "dataset_filepaths['pmc_custom_license'] = [os.path.join(path, e) for e in os.listdir(path) if e.endswith('.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a sample paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(numpy.random.choice(dataset_filepaths['pmc_custom_license']), 'r') as handle:\n",
    "    paper_data = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SARS Epidemiology Modeling',\n",
       " 'SARS Epidemiology Modeling',\n",
       " 'SARS Epidemiology Modeling',\n",
       " 'SARS Epidemiology Modeling',\n",
       " 'SARS Epidemiology Modeling',\n",
       " 'SARS Epidemiology Modeling',\n",
       " 'Guofa Zhou* and Guiyan Yan*',\n",
       " 'Diagnostic Criteria during SARS Outbreak in Hong Kong',\n",
       " 'Diagnostic Criteria during SARS Outbreak in Hong Kong',\n",
       " 'Diagnostic Criteria during SARS Outbreak in Hong Kong',\n",
       " 'Diagnostic Criteria during SARS Outbreak in Hong Kong',\n",
       " 'Diagnostic Criteria during SARS Outbreak in Hong Kong']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[e['section'] for e in paper_data['body_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = paper_data['body_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'cite_spans', 'ref_spans', 'section'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To the Editor: To assess the effectiveness of intervention measures during the recent severe acute respiratory syndrome (SARS) pandemic, Zhou and Yan (1) used Richards model, a logistic-type model, to fit the cumulative number of SARS cases reported daily in Singapore, Hong Kong, and Beijing. The key to using mathemati-cal models for SARS epidemiology is understanding the models (2) . In the Richards model (1) , the function F(S) in the model was described as measuring \"the effectiveness of intervention measures.\" The parameters in F(S), namely, the maximum cases load K and the exponent of deviation a, depict the actual progression of the epidemic as described by the reported data. In other words, the parameter estimates are used to quantify end results of the intervention measures implemented during the outbreaks. Simply put, the all-important question of \"what if?\" was not answered by their result. To gauge the effectiveness of intervention measures, one should consider a more complicated model with variable maximum case load and growth rate (r) that highlights the time-varying nature of an epidemic and its dependence on the intervention measures implemented during the epidemic.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(e['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'title': '', 'authors': []}\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(paper_data['metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03e352c35635f746ff112e5a766eefe10efb59b4'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_data['paper_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset_dict = {\n",
    "    'paper_id': [],\n",
    "    'text_segment': [],\n",
    "    'corresponding_section': [],\n",
    "    'dataset': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1606 [00:00<00:25, 62.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset: biorxiv_medrxiv \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1606/1606 [00:07<00:00, 223.37it/s]\n",
      "  0%|          | 9/18000 [00:00<03:42, 80.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset: comm_use_subset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [01:47<00:00, 167.28it/s] \n",
      "  0%|          | 1/3946 [00:00<08:02,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset: noncomm_use_subset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3946/3946 [00:22<00:00, 176.35it/s]\n",
      "  1%|          | 16/2852 [00:00<00:18, 153.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset: pmc_custom_license \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [00:11<00:00, 240.68it/s]\n"
     ]
    }
   ],
   "source": [
    "ignored_paper_count = 0\n",
    "for dataset in dataset_filepaths.keys():\n",
    "    print(\"processing dataset: {} \\n\".format(dataset))\n",
    "    for filepath in tqdm(dataset_filepaths[dataset]):\n",
    "        with open(filepath, 'r') as handle:\n",
    "            try:\n",
    "                paper_data = json.load(handle)\n",
    "            except Exception as e:\n",
    "                ignored_paper_count += 1\n",
    "                continue\n",
    "            paper_id = paper_data['paper_id']\n",
    "            for e in paper_data['body_text']:\n",
    "                section = e['section']\n",
    "                for text_segment in sent_tokenize(e['text']):\n",
    "                    final_dataset_dict['paper_id'].append(paper_id)\n",
    "                    final_dataset_dict['text_segment'].append(text_segment)\n",
    "                    final_dataset_dict['corresponding_section'].append(section)\n",
    "                    final_dataset_dict['dataset'].append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pandas.DataFrame(final_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.iloc[900:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv('/Volumes/samsung/2020-03-13/text_segment_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
